{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4871fd0f",
   "metadata": {},
   "source": [
    "# Feature Engineering for Rental Product Recommender\n",
    "\n",
    "This notebook implements advanced feature engineering techniques to enrich the dataset for the Transformers4Rec model.\n",
    "Inspired by \"Feature Engineering for Recommendation Systems\", we will focus on:\n",
    "1.  **Item Metadata**: Enriching item representations with Brand, Category, and Price.\n",
    "2.  **Session Context**: Extracting temporal and device-specific features.\n",
    "3.  **Counter Features**: Calculating global popularity metrics.\n",
    "\n",
    "## 1. Load Data\n",
    "We load the raw interaction logs and the product catalogs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b4b500a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading raw data...\n",
      "Loading product catalogs...\n",
      "Hits: 1721596, Visits: 323241\n",
      "New Products: 665, Old Products: 761\n",
      "Loading product catalogs...\n",
      "Hits: 1721596, Visits: 323241\n",
      "New Products: 665, Old Products: 761\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "# Load Raw Data\n",
    "print(\"Loading raw data...\")\n",
    "hits_df = pd.read_csv('data/metrika_hits.csv', low_memory=False)\n",
    "visits_df = pd.read_csv('data/metrika_visits.csv', low_memory=False)\n",
    "\n",
    "# Load Product Catalogs\n",
    "print(\"Loading product catalogs...\")\n",
    "new_products = pd.read_csv('data/new_site_products.csv')\n",
    "old_products = pd.read_csv('data/old_site_products.csv')\n",
    "\n",
    "print(f\"Hits: {len(hits_df)}, Visits: {len(visits_df)}\")\n",
    "print(f\"New Products: {len(new_products)}, Old Products: {len(old_products)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "929072bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Products with Metadata: 1400\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slug</th>\n",
       "      <th>brand</th>\n",
       "      <th>main_category</th>\n",
       "      <th>price_per_period_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>matras-red-castle-kokon-dlya-novorozhdennyh-co...</td>\n",
       "      <td>Red Castle</td>\n",
       "      <td>Коконы для новорожденных</td>\n",
       "      <td>1500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kokon-dlya-novorozhdennyh-matello-cocon-baby-l...</td>\n",
       "      <td>Matello</td>\n",
       "      <td>Коконы для новорожденных</td>\n",
       "      <td>1500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kokon-lyulka-dlya-novorozhdennyh-farla-baby-sh...</td>\n",
       "      <td>Farla</td>\n",
       "      <td>Коконы для новорожденных</td>\n",
       "      <td>1300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kacheli-shezlong-4moms-mamaroo-40-naprokat</td>\n",
       "      <td>4moms</td>\n",
       "      <td>Электрокачели</td>\n",
       "      <td>2200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kacheli-shezlong-4moms-mamaroo-30-naprokat</td>\n",
       "      <td>4moms</td>\n",
       "      <td>Электрокачели</td>\n",
       "      <td>2700.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                slug       brand  \\\n",
       "0  matras-red-castle-kokon-dlya-novorozhdennyh-co...  Red Castle   \n",
       "1  kokon-dlya-novorozhdennyh-matello-cocon-baby-l...     Matello   \n",
       "2  kokon-lyulka-dlya-novorozhdennyh-farla-baby-sh...       Farla   \n",
       "3         kacheli-shezlong-4moms-mamaroo-40-naprokat       4moms   \n",
       "4         kacheli-shezlong-4moms-mamaroo-30-naprokat       4moms   \n",
       "\n",
       "              main_category  price_per_period_week  \n",
       "0  Коконы для новорожденных                 1500.0  \n",
       "1  Коконы для новорожденных                 1500.0  \n",
       "2  Коконы для новорожденных                 1300.0  \n",
       "3             Электрокачели                 2200.0  \n",
       "4             Электрокачели                 2700.0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Unify Product Metadata\n",
    "# We need to map 'slug' (used in interactions) to metadata like Brand, Category, Price.\n",
    "\n",
    "# Select relevant columns and unify names\n",
    "cols_new = ['slug', 'brand', 'main_category', 'price_per_period_week']\n",
    "cols_old = ['slug', 'brand', 'main_category', 'price_per_period_week']\n",
    "\n",
    "# Normalize column names if they differ (checking file headers from previous steps)\n",
    "# new_site_products.csv has 'main_category', 'price_per_period_week'\n",
    "# old_site_products.csv has 'main_category', 'price_per_period_week'\n",
    "# It seems they match based on previous `head` output.\n",
    "\n",
    "products_combined = pd.concat([\n",
    "    new_products[cols_new],\n",
    "    old_products[cols_old]\n",
    "])\n",
    "\n",
    "# Drop duplicates (same slug might appear in both or multiple times)\n",
    "# We keep the first occurrence (arbitrary, but usually fine for static metadata)\n",
    "products_meta = products_combined.drop_duplicates(subset=['slug']).copy()\n",
    "\n",
    "# Fill missing values\n",
    "products_meta['brand'] = products_meta['brand'].fillna('Unknown')\n",
    "products_meta['main_category'] = products_meta['main_category'].fillna('Unknown')\n",
    "products_meta['price_per_period_week'] = products_meta['price_per_period_week'].fillna(0)\n",
    "\n",
    "print(f\"Unique Products with Metadata: {len(products_meta)}\")\n",
    "products_meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f9f9c7ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ID Maps...\n",
      "Parsing sessions...\n",
      "Mapping Slugs to Unified IDs...\n",
      "Valid Mapped Interactions: 331689\n",
      "Mapping Slugs to Unified IDs...\n",
      "Valid Mapped Interactions: 331689\n",
      "Session reconstruction complete.\n",
      "Session reconstruction complete.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>visit_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>slug</th>\n",
       "      <th>brand</th>\n",
       "      <th>main_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>463311640199432</td>\n",
       "      <td>495257463</td>\n",
       "      <td>avtokreslo-chicco-synthesis-xt-plus</td>\n",
       "      <td>Chicсo</td>\n",
       "      <td>Автокресла</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>714740689010850</td>\n",
       "      <td>495513634</td>\n",
       "      <td>piratskiy-korabl-elc</td>\n",
       "      <td>ELC</td>\n",
       "      <td>Машинки, рули и гаражи</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>714740689010850</td>\n",
       "      <td>495513634</td>\n",
       "      <td>piratskiy-korabl-elc</td>\n",
       "      <td>ELC</td>\n",
       "      <td>Машинки, рули и гаражи</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>714740689010850</td>\n",
       "      <td>495513634</td>\n",
       "      <td>piratskiy-korabl-elc</td>\n",
       "      <td>ELC</td>\n",
       "      <td>Машинки, рули и гаражи</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>771088661610548</td>\n",
       "      <td>495399966</td>\n",
       "      <td>kolyaska-transformer-2-v-1-chicco-urban-plus</td>\n",
       "      <td>Chicсo</td>\n",
       "      <td>Коляски</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          visit_id    item_id                                          slug  \\\n",
       "0  463311640199432  495257463           avtokreslo-chicco-synthesis-xt-plus   \n",
       "1  714740689010850  495513634                          piratskiy-korabl-elc   \n",
       "2  714740689010850  495513634                          piratskiy-korabl-elc   \n",
       "3  714740689010850  495513634                          piratskiy-korabl-elc   \n",
       "4  771088661610548  495399966  kolyaska-transformer-2-v-1-chicco-urban-plus   \n",
       "\n",
       "    brand           main_category  \n",
       "0  Chicсo              Автокресла  \n",
       "1     ELC  Машинки, рули и гаражи  \n",
       "2     ELC  Машинки, рули и гаражи  \n",
       "3     ELC  Машинки, рули и гаражи  \n",
       "4  Chicсo                 Коляски  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 3. Reconstruct Sessions and Map IDs (CORRECTED)\n",
    "# ==========================================\n",
    "import ast\n",
    "\n",
    "# --- A. Load Mapping Files ---\n",
    "print(\"Loading ID Maps...\")\n",
    "new_products_map = pd.read_csv('data/new_site_products.csv', usecols=['id', 'slug'])\n",
    "old_products_map = pd.read_csv('data/old_site_products.csv', usecols=['id', 'slug'])\n",
    "old_to_new_map = pd.read_csv('data/old_site_new_site_products.csv')\n",
    "\n",
    "# Create Dictionaries\n",
    "new_slug_to_id = dict(zip(new_products_map['slug'], new_products_map['id']))\n",
    "old_slug_to_id = dict(zip(old_products_map['slug'], old_products_map['id']))\n",
    "old_id_to_new_id = dict(zip(old_to_new_map['old_site_id'], old_to_new_map['new_site_id']))\n",
    "\n",
    "# Define Mapping Function\n",
    "def get_unified_id(slug):\n",
    "    if not isinstance(slug, str): return None\n",
    "    if slug in new_slug_to_id: return new_slug_to_id[slug]\n",
    "    if slug in old_slug_to_id:\n",
    "        old_id = old_slug_to_id[slug]\n",
    "        if old_id in old_id_to_new_id:\n",
    "            return old_id_to_new_id[old_id]\n",
    "    return None\n",
    "\n",
    "# --- B. Parse Sessions ---\n",
    "print(\"Parsing sessions...\")\n",
    "def parse_watch_ids(x):\n",
    "    try: return ast.literal_eval(x)\n",
    "    except: return []\n",
    "\n",
    "visits_df['watch_ids_list'] = visits_df['watch_ids'].apply(parse_watch_ids)\n",
    "session_hits = visits_df.explode('watch_ids_list').rename(columns={'watch_ids_list': 'watch_id'})\n",
    "\n",
    "session_hits['watch_id'] = session_hits['watch_id'].astype(str)\n",
    "hits_df['watch_id'] = hits_df['watch_id'].astype(str)\n",
    "\n",
    "full_data = session_hits.merge(hits_df, on='watch_id', how='inner')\n",
    "interactions = full_data[full_data['page_type'] == 'PRODUCT'].copy()\n",
    "\n",
    "# --- FIX IS HERE ---\n",
    "# Use 'date_time_x' because the merge created suffixes\n",
    "interactions['date_time'] = pd.to_datetime(interactions['date_time_x'])\n",
    "interactions = interactions.sort_values(['visit_id', 'date_time'])\n",
    "\n",
    "# --- C. APPLY MAPPING ---\n",
    "print(\"Mapping Slugs to Unified IDs...\")\n",
    "interactions['item_id'] = interactions['slug'].apply(get_unified_id)\n",
    "\n",
    "# Drop rows that couldn't be mapped\n",
    "interactions = interactions.dropna(subset=['item_id'])\n",
    "interactions['item_id'] = interactions['item_id'].astype(int)\n",
    "print(f\"Valid Mapped Interactions: {len(interactions)}\")\n",
    "\n",
    "# --- D. Merge Metadata ---\n",
    "interactions = interactions.merge(products_meta, left_on='slug', right_on='slug', how='left')\n",
    "\n",
    "# Fill missing\n",
    "interactions['brand'] = interactions['brand'].fillna('Unknown')\n",
    "interactions['main_category'] = interactions['main_category'].fillna('Unknown')\n",
    "interactions['price_per_period_week'] = interactions['price_per_period_week'].fillna(0)\n",
    "\n",
    "print(\"Session reconstruction complete.\")\n",
    "interactions[['visit_id', 'item_id', 'slug', 'brand', 'main_category']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f5a751e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enriched Interactions:\n",
      "          visit_id    item_id           date_time traffic_source   brand  \\\n",
      "0  463311640199432  495257463 2022-01-20 03:29:26             ad  Chicсo   \n",
      "1  714740689010850  495513634 2022-01-20 03:45:26         direct     ELC   \n",
      "2  714740689010850  495513634 2022-01-20 03:45:26         direct     ELC   \n",
      "3  714740689010850  495513634 2022-01-20 03:45:26         direct     ELC   \n",
      "4  771088661610548  495399966 2022-01-20 03:49:01             ad  Chicсo   \n",
      "\n",
      "            main_category  price_bucket  hour  day_of_week  is_weekend  \\\n",
      "0              Автокресла             2     3            3           0   \n",
      "1  Машинки, рули и гаражи             1     3            3           0   \n",
      "2  Машинки, рули и гаражи             1     3            3           0   \n",
      "3  Машинки, рули и гаражи             1     3            3           0   \n",
      "4                 Коляски             5     3            3           0   \n",
      "\n",
      "   item_popularity  category_popularity  \n",
      "0             1133                63506  \n",
      "1              356                 5490  \n",
      "2              356                 5490  \n",
      "3              356                 5490  \n",
      "4             6101                77827  \n",
      "Saved to data/enriched_interactions.parquet\n"
     ]
    }
   ],
   "source": [
    "# 4. Feature Engineering\n",
    "\n",
    "# A. Temporal Features\n",
    "interactions['hour'] = interactions['date_time'].dt.hour\n",
    "interactions['day_of_week'] = interactions['date_time'].dt.dayofweek\n",
    "interactions['is_weekend'] = interactions['day_of_week'].isin([5, 6]).astype(int)\n",
    "\n",
    "# B. Counter Features (Global Popularity)\n",
    "# Item Popularity\n",
    "item_counts = interactions['item_id'].value_counts()\n",
    "interactions['item_popularity'] = interactions['item_id'].map(item_counts)\n",
    "\n",
    "# Category Popularity\n",
    "category_counts = interactions['main_category'].value_counts()\n",
    "interactions['category_popularity'] = interactions['main_category'].map(category_counts)\n",
    "\n",
    "# C. Price Binning (Optional, but good for categorical models)\n",
    "# We can keep price as continuous or bin it. Let's keep it continuous for now, \n",
    "# but T4Rec might handle categorical better if we don't normalize.\n",
    "# Let's create a 'price_bucket' feature.\n",
    "interactions['price_bucket'] = pd.qcut(interactions['price_per_period_week'], q=10, labels=False, duplicates='drop').fillna(0).astype(int)\n",
    "\n",
    "# Select Final Columns\n",
    "# We keep the original IDs and the new features\n",
    "final_cols = [\n",
    "    'visit_id', 'item_id', 'date_time', \n",
    "    'traffic_source', 'region_city', # Original Context\n",
    "    'brand', 'main_category', 'price_bucket', # Item Metadata\n",
    "    'hour', 'day_of_week', 'is_weekend', # Temporal\n",
    "    'device_category', 'mobile_phone', # Device\n",
    "    'item_popularity', 'category_popularity' # Counters\n",
    "]\n",
    "\n",
    "# Ensure columns exist (handle potential missing ones from merge)\n",
    "available_cols = [c for c in final_cols if c in interactions.columns]\n",
    "enriched_interactions = interactions[available_cols]\n",
    "\n",
    "print(\"Enriched Interactions:\")\n",
    "print(enriched_interactions.head())\n",
    "\n",
    "# Save to Parquet for T4Rec\n",
    "# We save this as a new \"raw\" file for the T4Rec notebook to pick up\n",
    "enriched_interactions.to_parquet('data/enriched_interactions.parquet', index=False)\n",
    "print(\"Saved to data/enriched_interactions.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "40ce1af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Add-to-Cart events (this might take a moment)...\n",
      "'ecommerce' column found in interactions.\n",
      "Total Add-to-Cart events found: 1062\n",
      "Total Add-to-Cart events found: 1062\n",
      "Top 5 Items by Conversion Rate (min 10 views):\n",
      "        item_id  total_views  total_adds  conversion_rate\n",
      "113   463480453           24           5         0.208333\n",
      "590  1526105009           27           5         0.185185\n",
      "181   463480568           12           2         0.166667\n",
      "55    463480362          130          15         0.115385\n",
      "34    463480273          149          16         0.107383\n",
      "Top 5 Items by Conversion Rate (min 10 views):\n",
      "        item_id  total_views  total_adds  conversion_rate\n",
      "113   463480453           24           5         0.208333\n",
      "590  1526105009           27           5         0.185185\n",
      "181   463480568           12           2         0.166667\n",
      "55    463480362          130          15         0.115385\n",
      "34    463480273          149          16         0.107383\n",
      "Saved enriched data with Conversion Rates.\n",
      "Final columns: ['visit_id', 'item_id', 'date_time', 'traffic_source', 'region_city', 'brand', 'main_category', 'price_bucket', 'hour', 'day_of_week', 'is_weekend', 'device_category', 'mobile_phone', 'item_popularity', 'category_popularity', 'conversion_rate']\n",
      "Saved enriched data with Conversion Rates.\n",
      "Final columns: ['visit_id', 'item_id', 'date_time', 'traffic_source', 'region_city', 'brand', 'main_category', 'price_bucket', 'hour', 'day_of_week', 'is_weekend', 'device_category', 'mobile_phone', 'item_popularity', 'category_popularity', 'conversion_rate']\n"
     ]
    }
   ],
   "source": [
    "# 5. Advanced Feature Engineering: Conversion Rates (Phase 2B)\n",
    "\n",
    "import json\n",
    "import ast\n",
    "\n",
    "# Function to parse ecommerce JSON and extract \"add\" events\n",
    "def extract_add_to_cart(row):\n",
    "    ecommerce_data = row['ecommerce']\n",
    "    if pd.isna(ecommerce_data) or ecommerce_data == '':\n",
    "        return 0\n",
    "    \n",
    "    try:\n",
    "        # The data is often a string representation of a list of dicts\n",
    "        if isinstance(ecommerce_data, str):\n",
    "            try:\n",
    "                data = json.loads(ecommerce_data)\n",
    "            except:\n",
    "                try:\n",
    "                    data = ast.literal_eval(ecommerce_data)\n",
    "                except:\n",
    "                    return 0\n",
    "        else:\n",
    "            data = ecommerce_data\n",
    "            \n",
    "        # Check for list or dict\n",
    "        if isinstance(data, list):\n",
    "            for event in data:\n",
    "                if 'add' in event:\n",
    "                    return 1\n",
    "        elif isinstance(data, dict):\n",
    "            if 'add' in data:\n",
    "                return 1\n",
    "                \n",
    "        return 0\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "print(\"Extracting Add-to-Cart events (this might take a moment)...\")\n",
    "\n",
    "# Check if 'ecommerce' column is already in interactions\n",
    "if 'ecommerce' in interactions.columns:\n",
    "    print(\"'ecommerce' column found in interactions.\")\n",
    "    interactions_with_ecommerce = interactions.copy()\n",
    "else:\n",
    "    print(\"'ecommerce' column NOT found. Merging from hits_df...\")\n",
    "    interactions_with_ecommerce = interactions.merge(hits_df[['watch_id', 'ecommerce']], on='watch_id', how='left')\n",
    "\n",
    "# Apply extraction\n",
    "interactions_with_ecommerce['is_add_to_cart'] = interactions_with_ecommerce.apply(extract_add_to_cart, axis=1)\n",
    "\n",
    "print(f\"Total Add-to-Cart events found: {interactions_with_ecommerce['is_add_to_cart'].sum()}\")\n",
    "\n",
    "# Calculate Conversion Rates per Item\n",
    "item_stats = interactions_with_ecommerce.groupby('item_id').agg(\n",
    "    total_views=('visit_id', 'count'),\n",
    "    total_adds=('is_add_to_cart', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "item_stats['conversion_rate'] = item_stats['total_adds'] / item_stats['total_views']\n",
    "item_stats['conversion_rate'] = item_stats['conversion_rate'].fillna(0)\n",
    "\n",
    "# Merge back to interactions\n",
    "if 'conversion_rate' in interactions.columns:\n",
    "    interactions = interactions.drop(columns=['conversion_rate'])\n",
    "\n",
    "interactions = interactions.merge(item_stats[['item_id', 'conversion_rate']], on='item_id', how='left')\n",
    "\n",
    "print(\"Top 5 Items by Conversion Rate (min 10 views):\")\n",
    "print(item_stats[item_stats['total_views'] > 10].sort_values('conversion_rate', ascending=False).head())\n",
    "\n",
    "# Fix column names (handle _x suffixes from merge)\n",
    "# We prefer the session-level data (from visits_df, which was left side _x)\n",
    "rename_map = {\n",
    "    'region_city_x': 'region_city',\n",
    "    'device_category_x': 'device_category',\n",
    "    'mobile_phone_x': 'mobile_phone'\n",
    "}\n",
    "interactions = interactions.rename(columns=rename_map)\n",
    "\n",
    "# Update final columns to include conversion_rate\n",
    "if 'conversion_rate' not in final_cols:\n",
    "    final_cols.append('conversion_rate')\n",
    "\n",
    "# Ensure all final_cols exist\n",
    "missing_cols = [c for c in final_cols if c not in interactions.columns]\n",
    "if missing_cols:\n",
    "    print(f\"Warning: Missing columns {missing_cols}. Checking for alternatives...\")\n",
    "    # Try to find them with suffixes\n",
    "    for col in missing_cols:\n",
    "        if col + '_x' in interactions.columns:\n",
    "            interactions[col] = interactions[col + '_x']\n",
    "            print(f\"Recovered {col} from {col}_x\")\n",
    "        elif col + '_y' in interactions.columns:\n",
    "            interactions[col] = interactions[col + '_y']\n",
    "            print(f\"Recovered {col} from {col}_y\")\n",
    "\n",
    "# Re-save enriched data\n",
    "# Use intersection of available columns to avoid KeyError\n",
    "available_cols = [c for c in final_cols if c in interactions.columns]\n",
    "enriched_interactions = interactions[available_cols]\n",
    "enriched_interactions.to_parquet('data/enriched_interactions.parquet', index=False)\n",
    "print(\"Saved enriched data with Conversion Rates.\")\n",
    "print(f\"Final columns: {enriched_interactions.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1c9fb6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating User History Features...\n",
      "User History Features Added:\n",
      "         client_id             visit_id  user_session_rank  \\\n",
      "0       1335930034  7155825714110136555                  1   \n",
      "1   16506143675549  2091271487556157575                  1   \n",
      "2  164482580996736   573835779580362831                  1   \n",
      "3  164482580996736   573835779580362831                  1   \n",
      "4  164482580996736   573835779580362831                  1   \n",
      "5  164482580996736   573835779580362831                  1   \n",
      "6  164482580996736   573835779580362831                  1   \n",
      "7  164949568311760  1798015212634767546                  1   \n",
      "8  164949568311760  1798015212634767546                  1   \n",
      "9  164949568311760  1798015212634767546                  1   \n",
      "\n",
      "   days_since_last_session  is_new_user  \n",
      "0                     -1.0            1  \n",
      "1                     -1.0            1  \n",
      "2                     -1.0            1  \n",
      "3                     -1.0            1  \n",
      "4                     -1.0            1  \n",
      "5                     -1.0            1  \n",
      "6                     -1.0            1  \n",
      "7                     -1.0            1  \n",
      "8                     -1.0            1  \n",
      "9                     -1.0            1  \n",
      "User History Features Added:\n",
      "         client_id             visit_id  user_session_rank  \\\n",
      "0       1335930034  7155825714110136555                  1   \n",
      "1   16506143675549  2091271487556157575                  1   \n",
      "2  164482580996736   573835779580362831                  1   \n",
      "3  164482580996736   573835779580362831                  1   \n",
      "4  164482580996736   573835779580362831                  1   \n",
      "5  164482580996736   573835779580362831                  1   \n",
      "6  164482580996736   573835779580362831                  1   \n",
      "7  164949568311760  1798015212634767546                  1   \n",
      "8  164949568311760  1798015212634767546                  1   \n",
      "9  164949568311760  1798015212634767546                  1   \n",
      "\n",
      "   days_since_last_session  is_new_user  \n",
      "0                     -1.0            1  \n",
      "1                     -1.0            1  \n",
      "2                     -1.0            1  \n",
      "3                     -1.0            1  \n",
      "4                     -1.0            1  \n",
      "5                     -1.0            1  \n",
      "6                     -1.0            1  \n",
      "7                     -1.0            1  \n",
      "8                     -1.0            1  \n",
      "9                     -1.0            1  \n",
      "Saved enriched data with User History.\n",
      "Final columns: ['visit_id', 'item_id', 'date_time', 'traffic_source', 'region_city', 'brand', 'main_category', 'price_bucket', 'hour', 'day_of_week', 'is_weekend', 'device_category', 'mobile_phone', 'item_popularity', 'category_popularity', 'conversion_rate', 'user_session_rank', 'days_since_last_session', 'is_new_user']\n",
      "Saved enriched data with User History.\n",
      "Final columns: ['visit_id', 'item_id', 'date_time', 'traffic_source', 'region_city', 'brand', 'main_category', 'price_bucket', 'hour', 'day_of_week', 'is_weekend', 'device_category', 'mobile_phone', 'item_popularity', 'category_popularity', 'conversion_rate', 'user_session_rank', 'days_since_last_session', 'is_new_user']\n"
     ]
    }
   ],
   "source": [
    "# 6. User History Features (Phase 3)\n",
    "\n",
    "print(\"Calculating User History Features...\")\n",
    "\n",
    "# Ensure client_id is available and consistent\n",
    "if 'client_id' not in interactions.columns:\n",
    "    if 'client_id_x' in interactions.columns:\n",
    "        interactions['client_id'] = interactions['client_id_x']\n",
    "    elif 'client_id_y' in interactions.columns:\n",
    "        interactions['client_id'] = interactions['client_id_y']\n",
    "\n",
    "# Sort by User and Time to ensure correct history calculation\n",
    "interactions = interactions.sort_values(['client_id', 'date_time'])\n",
    "\n",
    "# 1. Session Rank (1st session, 2nd session, etc.)\n",
    "# We group by client_id and rank the visit_ids by time\n",
    "# dense rank means 1, 2, 3... with no gaps\n",
    "interactions['user_session_rank'] = interactions.groupby('client_id')['visit_id'].transform(lambda x: x.factorize()[0] + 1)\n",
    "\n",
    "# 2. Days Since Last Session (Recency)\n",
    "# We need a dataframe of unique sessions per user with their timestamps\n",
    "user_sessions = interactions[['client_id', 'visit_id', 'date_time']].drop_duplicates(subset=['visit_id'])\n",
    "user_sessions = user_sessions.sort_values(['client_id', 'date_time'])\n",
    "\n",
    "# Calculate time difference between current and previous session\n",
    "user_sessions['prev_session_time'] = user_sessions.groupby('client_id')['date_time'].shift(1)\n",
    "user_sessions['days_since_last_session'] = (user_sessions['date_time'] - user_sessions['prev_session_time']).dt.total_seconds() / (24 * 3600)\n",
    "user_sessions['days_since_last_session'] = user_sessions['days_since_last_session'].fillna(-1) # -1 for first session\n",
    "\n",
    "# Merge recency back to interactions\n",
    "interactions = interactions.merge(user_sessions[['visit_id', 'days_since_last_session']], on='visit_id', how='left')\n",
    "\n",
    "# 3. Is New User (from raw data, double check)\n",
    "if 'is_new_user' not in interactions.columns:\n",
    "    # Try to recover from raw visits if possible, or infer from rank\n",
    "    interactions['is_new_user'] = (interactions['user_session_rank'] == 1).astype(int)\n",
    "else:\n",
    "    # Ensure it's numeric\n",
    "    interactions['is_new_user'] = interactions['is_new_user'].astype(int)\n",
    "\n",
    "print(\"User History Features Added:\")\n",
    "print(interactions[['client_id', 'visit_id', 'user_session_rank', 'days_since_last_session', 'is_new_user']].head(10))\n",
    "\n",
    "# Add to final columns\n",
    "new_history_cols = ['user_session_rank', 'days_since_last_session', 'is_new_user']\n",
    "for col in new_history_cols:\n",
    "    if col not in final_cols:\n",
    "        final_cols.append(col)\n",
    "\n",
    "# Re-save enriched data\n",
    "available_cols = [c for c in final_cols if c in interactions.columns]\n",
    "enriched_interactions = interactions[available_cols]\n",
    "enriched_interactions.to_parquet('data/enriched_interactions.parquet', index=False)\n",
    "print(\"Saved enriched data with User History.\")\n",
    "print(f\"Final columns: {enriched_interactions.columns.tolist()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "t4rec_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
